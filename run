#!/usr/bin/env python3
"""Top-level runner script for model evaluation tool.

Usage:
  ./run install   # installs requirements
  ./run test      # runs test suite
  ./run <url-file> # analyzes URLs and outputs NDJSON
"""
from __future__ import annotations

import argparse
import json
import logging
import os
import re
import subprocess
import sys
import time
from pathlib import Path
from typing import Dict, Any, List, Tuple

# Add src to path for imports
ROOT = Path(__file__).parent.absolute()
SRC_DIR = ROOT / "src"
sys.path.insert(0, str(SRC_DIR))

# Import after path setup
try:
    from url_handler import handle_input_file
except ImportError:
    # Fallback import
    import url_handler


def setup_logging() -> None:
    """Configure logging based on environment variables."""
    log_file = os.environ.get("LOG_FILE", "")
    try:
        log_level = int(os.environ.get("LOG_LEVEL", "0"))
    except (ValueError, TypeError):
        log_level = 0

    if log_file:
        # Ensure directory exists
        log_dir = os.path.dirname(log_file)
        if log_dir:
            os.makedirs(log_dir, exist_ok=True)
        
        if log_level == 0:
            # Create empty file for silent mode
            with open(log_file, 'w') as f:
                pass
        else:
            # Configure logging
            level = logging.INFO if log_level == 1 else logging.DEBUG
            logging.basicConfig(
                filename=log_file,
                filemode='w',  # Overwrite each run
                level=level,
                format='%(asctime)s %(levelname)s %(message)s',
                datefmt='%Y-%m-%dT%H:%M:%SZ'
            )
            
            # Also set levels for specific loggers
            for logger_name in ['url_handler', 'HF_API_Integration', 'run']:
                logger = logging.getLogger(logger_name)
                logger.setLevel(level)


def run_install() -> int:
    """Install dependencies."""
    req_file = ROOT / "requirements.txt"
    if not req_file.exists():
        print("requirements.txt not found", file=sys.stderr)
        return 1
    
    cmd = [sys.executable, "-m", "pip", "install", "--user", "-r", str(req_file)]
    result = subprocess.run(cmd, capture_output=True, text=True)
    
    if result.returncode != 0:
        print("Installation failed:", result.stderr, file=sys.stderr)
        return 1
    return 0


def run_tests() -> int:
    """Run test suite and print results in exact required format."""
    # Run pytest with coverage
    cmd = [
        sys.executable, "-m", "pytest",
        "tests/",  # Test directory
        "--cov=src",
        "--cov-report=term",
        "-v",
        "--tb=short",
        "--no-header",
        "--disable-warnings"
    ]
    
    try:
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
    except subprocess.TimeoutExpired:
        print("0/0 test cases passed. 0% line coverage achieved.")
        return 1
    except Exception as e:
        print(f"0/0 test cases passed. 0% line coverage achieved.")
        return 1
    
    output = result.stdout + result.stderr
    
    # Count test results
    passed = 0
    failed = 0
    errors = 0
    
    # Look for pytest summary line (e.g., "== 25 passed, 2 failed ==")
    summary_match = re.search(
        r'=+\s*(\d+)\s+passed(?:,\s*(\d+)\s+failed)?(?:,\s*(\d+)\s+error)?',
        output
    )
    
    if summary_match:
        passed = int(summary_match.group(1) or 0)
        failed = int(summary_match.group(2) or 0)
        errors = int(summary_match.group(3) or 0)
    else:
        # Fallback: count individual test results
        passed = len(re.findall(r'\s+PASSED', output))
        failed = len(re.findall(r'\s+FAILED', output))
        errors = len(re.findall(r'\s+ERROR', output))
    
    total = passed + failed + errors
    
    # Extract coverage percentage
    coverage = 0
    cov_match = re.search(r'TOTAL\s+\d+\s+\d+\s+(\d+)%', output)
    if cov_match:
        coverage = int(cov_match.group(1))
    else:
        # Alternative format
        cov_match = re.search(r'TOTAL.*?(\d+)%', output)
        if cov_match:
            coverage = int(cov_match.group(1))
    
    # Print in EXACT required format
    print(f"{passed}/{total} test cases passed. {coverage}% line coverage achieved.")
    
    # Return 0 only if all tests passed
    return 0 if failed == 0 and errors == 0 else 1


def process_url_file(filepath: str) -> int:
    """Process URL file and output NDJSON for models only."""
    try:
        # Use url_handler to process the file
        results = handle_input_file(filepath)
        
        if not results:
            # Empty results, but not an error
            return 0
        
        # Output NDJSON for MODEL entries only
        for record in results:
            # Only output MODEL category entries
            if record.get("category", "").upper() != "MODEL":
                continue
            
            # Ensure all required fields with correct types
            output_record = {
                "name": str(record.get("name", "")),
                "category": "MODEL",
                "net_score": float(record.get("net_score", 0.0)),
                "net_score_latency": int(record.get("net_score_latency", 0)),
                "ramp_up_time": float(record.get("ramp_up_time", 0.0)),
                "ramp_up_time_latency": int(record.get("ramp_up_time_latency", 0)),
                "bus_factor": float(record.get("bus_factor", 0.0)),
                "bus_factor_latency": int(record.get("bus_factor_latency", 0)),
                "performance_claims": float(record.get("performance_claims", 0.0)),
                "performance_claims_latency": int(record.get("performance_claims_latency", 0)),
                "license": float(record.get("license", 0.0)),
                "license_latency": int(record.get("license_latency", 0)),
                "size_score": record.get("size_score", {
                    "raspberry_pi": 0.0,
                    "jetson_nano": 0.0,
                    "desktop_pc": 0.0,
                    "aws_server": 0.0
                }),
                "size_score_latency": int(record.get("size_score_latency", 0)),
                "dataset_and_code_score": float(record.get("dataset_and_code_score", 0.0)),
                "dataset_and_code_score_latency": int(record.get("dataset_and_code_score_latency", 0)),
                "dataset_quality": float(record.get("dataset_quality", 0.0)),
                "dataset_quality_latency": int(record.get("dataset_quality_latency", 0)),
                "code_quality": float(record.get("code_quality", 0.0)),
                "code_quality_latency": int(record.get("code_quality_latency", 0))
            }
            
            # Ensure size_score values are floats
            if isinstance(output_record["size_score"], dict):
                for device in ["raspberry_pi", "jetson_nano", "desktop_pc", "aws_server"]:
                    if device in output_record["size_score"]:
                        output_record["size_score"][device] = float(
                            output_record["size_score"][device]
                        )
                    else:
                        output_record["size_score"][device] = 0.0
            
            # Output as single-line NDJSON
            print(json.dumps(output_record, ensure_ascii=False))
        
        return 0
        
    except FileNotFoundError:
        print(f"Error: File {filepath} not found", file=sys.stderr)
        return 1
    except Exception as e:
        print(f"Error processing URL file: {e}", file=sys.stderr)
        logging.error(f"Error processing URL file: {e}")
        return 1


def main(argv: List[str] = None) -> int:
    """Main entry point."""
    # Set up logging first
    setup_logging()
    logger = logging.getLogger("run")
    
    # Parse arguments
    parser = argparse.ArgumentParser(prog="run", add_help=False)
    parser.add_argument("command", nargs="?")
    parser.add_argument("--output", "-o", help=argparse.SUPPRESS)
    parser.add_argument("--pretty", action="store_true", help=argparse.SUPPRESS)
    
    try:
        args = parser.parse_args(argv)
    except SystemExit:
        return 2
    
    if not args.command:
        print("Usage: ./run [install|test|URL_FILE]", file=sys.stderr)
        return 2
    
    # Log the command
    logger.info(f"Running command: {args.command}")
    
    # Handle commands
    if args.command == "install":
        logger.info("Running install")
        return run_install()
    
    elif args.command == "test":
        logger.info("Running tests")
        return run_tests()
    
    elif os.path.isfile(args.command):
        # Process URL file
        logger.info(f"Processing URL file: {args.command}")
        return process_url_file(args.command)
    
    else:
        print(f"Error: Unknown command or file not found: {args.command}", file=sys.stderr)
        return 1


if __name__ == "__main__":
    try:
        sys.exit(main())
    except KeyboardInterrupt:
        sys.exit(130)
    except Exception as e:
        print(f"Fatal error: {e}", file=sys.stderr)
        sys.exit(1)